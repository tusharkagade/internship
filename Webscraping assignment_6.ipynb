{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cadea633",
   "metadata": {},
   "source": [
    "# 1. Scrape  the  details  of  most  viewed  videos  on  YouTube  from  Wikipedia.  Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:  A) Rank   B) Name   C) Artist   D) Upload date  E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b622933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56519026",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b320108",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0c7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Artist = []\n",
    "Upload_Date = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991b263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "for i in name_tags:\n",
    "    name_title=i.text\n",
    "    Name.append(name_title)\n",
    "    \n",
    "artist_tags=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "for i in artist_tags:\n",
    "    artist_title=i.text\n",
    "    Artist.append(artist_title)\n",
    "    \n",
    "date_tags=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "for i in date_tags:\n",
    "    date_title=i.text\n",
    "    Upload_Date.append(date_title)\n",
    "    \n",
    "views_tags=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "for i in views_tags:\n",
    "    views_title=i.text\n",
    "    Views.append(views_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01461196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Artist),len(Upload_Date),len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832c0c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>14.32</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.41</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.89</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.66</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Shape of You\"[20]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.23</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"See You Again\"[23]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.22</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Wheels on the Bus\"[28]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.01</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.75</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.18</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>5.10</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.09</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.59</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[38]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.57</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Axel F\"[39]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.45</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Sugar\"[40]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>4.02</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>4.01</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Counting Stars\"[42]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>4.00</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.98</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.98</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.89</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Sorry\"[46]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.78</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[47]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.77</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.76</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.75</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.70</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.70</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.64</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.60</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.58</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.57</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name  \\\n",
       "0                             \"Baby Shark Dance\"[7]   \n",
       "1                                   \"Despacito\"[10]   \n",
       "2                        \"Johny Johny Yes Papa\"[18]   \n",
       "3                                   \"Bath Song\"[19]   \n",
       "4                                \"Shape of You\"[20]   \n",
       "5                               \"See You Again\"[23]   \n",
       "6                           \"Wheels on the Bus\"[28]   \n",
       "7                 \"Phonics Song with Two Words\"[29]   \n",
       "8                                 \"Uptown Funk\"[30]   \n",
       "9                               \"Gangnam Style\"[31]   \n",
       "10  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
       "11                             \"Dame Tu Cosita\"[37]   \n",
       "12   \"Masha and the Bear – Recipe for Disaster\"[38]   \n",
       "13                                     \"Axel F\"[39]   \n",
       "14                                      \"Sugar\"[40]   \n",
       "15                        \"Baa Baa Black Sheep\"[41]   \n",
       "16                             \"Counting Stars\"[42]   \n",
       "17                             \"Lakdi Ki Kathi\"[43]   \n",
       "18                                       \"Roar\"[44]   \n",
       "19           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "20                                      \"Sorry\"[46]   \n",
       "21                      \"Shree Hanuman Chalisa\"[47]   \n",
       "22          \"Humpty the train on a fruits ride\"[48]   \n",
       "23                          \"Thinking Out Loud\"[49]   \n",
       "24                                    \"Perfect\"[50]   \n",
       "25                                 \"Dark Horse\"[51]   \n",
       "26                                 \"Let Her Go\"[52]   \n",
       "27                                      \"Faded\"[53]   \n",
       "28                             \"Girls Like You\"[54]   \n",
       "29                                    \"Lean On\"[55]   \n",
       "\n",
       "                                               Artist Upload_Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories       14.32   \n",
       "1                                          Luis Fonsi        8.41   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs        6.89   \n",
       "3                          Cocomelon - Nursery Rhymes        6.66   \n",
       "4                                          Ed Sheeran        6.23   \n",
       "5                                         Wiz Khalifa        6.22   \n",
       "6                          Cocomelon - Nursery Rhymes        6.01   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs        5.75   \n",
       "8                                         Mark Ronson        5.18   \n",
       "9                                                 Psy        5.10   \n",
       "10                                        Miroshka TV        5.09   \n",
       "11                                      Ultra Records        4.59   \n",
       "12                                         Get Movies        4.57   \n",
       "13                                         Crazy Frog        4.45   \n",
       "14                                           Maroon 5        4.02   \n",
       "15                         Cocomelon - Nursery Rhymes        4.01   \n",
       "16                                        OneRepublic        4.00   \n",
       "17                                       Jingle Toons        3.98   \n",
       "18                                         Katy Perry        3.98   \n",
       "19                                            Shakira        3.89   \n",
       "20                                      Justin Bieber        3.78   \n",
       "21                              T-Series Bhakti Sagar        3.77   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs        3.76   \n",
       "23                                         Ed Sheeran        3.75   \n",
       "24                                         Ed Sheeran        3.70   \n",
       "25                                         Katy Perry        3.70   \n",
       "26                                          Passenger        3.64   \n",
       "27                                        Alan Walker        3.60   \n",
       "28                                           Maroon 5        3.58   \n",
       "29                               Major Lazer Official        3.57   \n",
       "\n",
       "                Views  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9       July 15, 2012  \n",
       "10  February 27, 2018  \n",
       "11      April 5, 2018  \n",
       "12   January 31, 2012  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15      June 25, 2018  \n",
       "16       May 31, 2013  \n",
       "17      June 14, 2018  \n",
       "18  September 5, 2013  \n",
       "19       June 4, 2010  \n",
       "20   October 22, 2015  \n",
       "21       May 10, 2011  \n",
       "22   January 26, 2018  \n",
       "23    October 7, 2014  \n",
       "24   November 9, 2017  \n",
       "25  February 20, 2014  \n",
       "26      July 25, 2012  \n",
       "27   December 3, 2015  \n",
       "28       May 31, 2018  \n",
       "29     March 22, 2015  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Name':Name,'Artist':Artist,'Upload_Date':Upload_Date,'Views':Views})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce9bfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf4117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc1a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c134bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd729cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8276b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b3556ad",
   "metadata": {},
   "source": [
    "# 2.  Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/. You need to find following details:  A) Series   B) Place   C) Date   D) Time   \n",
    "# Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7fd6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import time \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0b3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45873d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0932fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mens=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/li/a[1]')\n",
    "Mens.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a0334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fixtures=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "Fixtures.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8449808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Series =[]\n",
    "Place =[]\n",
    "Date =[]\n",
    "Time =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c54d3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_tags=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in series_tags:\n",
    "    series_title=i.text\n",
    "    Series.append(series_title)\n",
    "    \n",
    "place_tags=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in place_tags:\n",
    "    place_title=i.text\n",
    "    Place.append(place_title)\n",
    "    \n",
    "date_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in date_tags:\n",
    "    date_title=i.text\n",
    "    Date.append(date_title)\n",
    "    \n",
    "time_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time_tags:\n",
    "    time_title=i.text\n",
    "    Time.append(time_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a1bf1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(Series),len(Place),len(Date),len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2006c040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>place</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium,</td>\n",
       "      <td>6 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium,</td>\n",
       "      <td>9 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium,</td>\n",
       "      <td>5 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium,</td>\n",
       "      <td>9 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium,</td>\n",
       "      <td>12 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Central Broward Park &amp; Broward County Stadium,...</td>\n",
       "      <td>15 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           series  \\\n",
       "0  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "1  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "2                     ICC MENS T20 WORLD CUP 2024   \n",
       "3                     ICC MENS T20 WORLD CUP 2024   \n",
       "4                     ICC MENS T20 WORLD CUP 2024   \n",
       "5                     ICC MENS T20 WORLD CUP 2024   \n",
       "6                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "7                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "8                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                               place           date  \\\n",
       "0              Sylhet International Cricket Stadium,    6 MAY, 2024   \n",
       "1              Sylhet International Cricket Stadium,    9 MAY, 2024   \n",
       "2       Nassau County International Cricket Stadium,   5 JUNE, 2024   \n",
       "3       Nassau County International Cricket Stadium,   9 JUNE, 2024   \n",
       "4       Nassau County International Cricket Stadium,  12 JUNE, 2024   \n",
       "5  Central Broward Park & Broward County Stadium,...  15 JUNE, 2024   \n",
       "6                                Harare Sports Club,   6 JULY, 2024   \n",
       "7                                Harare Sports Club,   7 JULY, 2024   \n",
       "8                                Harare Sports Club,  10 JULY, 2024   \n",
       "\n",
       "          time  \n",
       "0  3:30 PM IST  \n",
       "1  3:30 PM IST  \n",
       "2  8:00 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  \n",
       "6  8:00 PM IST  \n",
       "7  8:00 PM IST  \n",
       "8  8:00 PM IST  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'series':Series,'place':Place,'date':Date,'time':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717af51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a56799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e2cd10",
   "metadata": {},
   "source": [
    "# 3.  Scrape the details of State-wise GDP of India from statisticstime.com.   Url = http://statisticstimes.com/ You have to find following details: A) Rank   B)State  C) GSDP(18-19)- at current prices   D) GSDP(19-20)- at current prices   E) Share(18-19)   F) GDP ( billion) \n",
    "# Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3063bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebdac9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75780dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5700a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e0d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "State = []\n",
    "GSDP_2021_2022 = []\n",
    "GSDP_2022_2023 = []\n",
    "Share = []\n",
    "GDP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "112f2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[1]')\n",
    "for i in rank_tags:\n",
    "    rank_title=i.text\n",
    "    Rank.append(rank_title)\n",
    "    \n",
    "state_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[2]')\n",
    "for i in state_tags:\n",
    "    state_title=i.text\n",
    "    State.append(state_title)\n",
    "    \n",
    "gsdp_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[5]')\n",
    "for i in gsdp_tags:\n",
    "    gsdp_title=i.text\n",
    "    GSDP_2021_2022.append(gsdp_title)\n",
    "    \n",
    "gsdp_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[9]')\n",
    "for i in gsdp_tags:\n",
    "    gsdp_title=i.text\n",
    "    GSDP_2022_2023.append(gsdp_title)\n",
    "    \n",
    "share_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[6]')\n",
    "for i in share_tags:\n",
    "    share_title=i.text\n",
    "    Share.append(share_title)\n",
    "    \n",
    "gdp_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[7]')\n",
    "for i in gdp_tags:\n",
    "    gdp_title=i.text\n",
    "    GDP.append(gdp_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "805d3216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 66 66 66 66 66\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(State),len(GSDP_2021_2022),len(GSDP_2022_2023),len(Share),len(GDP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b58a4399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_2021_2022</th>\n",
       "      <th>GSDP_2022_2023</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>-</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>1,453,321</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,978,094</td>\n",
       "      <td>1,335,052</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,975,595</td>\n",
       "      <td>1,318,027</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,928,683</td>\n",
       "      <td>1,475,629</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,329,238</td>\n",
       "      <td>839,805</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,193,489</td>\n",
       "      <td>784,655</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,148,471</td>\n",
       "      <td>764,685</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,124,204</td>\n",
       "      <td>715,157</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,092,964</td>\n",
       "      <td>622,908</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>934,542</td>\n",
       "      <td>616,189</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>881,336</td>\n",
       "      <td>625,981</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>868,905</td>\n",
       "      <td>587,198</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>662,886</td>\n",
       "      <td>464,574</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>650,302</td>\n",
       "      <td>442,473</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>617,192</td>\n",
       "      <td>462,053</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>411,454</td>\n",
       "      <td>300,799</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>410,525</td>\n",
       "      <td>302,119</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>358,863</td>\n",
       "      <td>259,800</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>267,143</td>\n",
       "      <td>198,341</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>193,352</td>\n",
       "      <td>129,573</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>172,162</td>\n",
       "      <td>133,372</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>84,266</td>\n",
       "      <td>59,867</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>62,550</td>\n",
       "      <td>42,997</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>46,096</td>\n",
       "      <td>33,879</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>43,810</td>\n",
       "      <td>28,849</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>38,785</td>\n",
       "      <td>25,209</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>37,557</td>\n",
       "      <td>22,144</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>36,594</td>\n",
       "      <td>-</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>34,775</td>\n",
       "      <td>21,085</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>31,038</td>\n",
       "      <td>18,993</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>27,824</td>\n",
       "      <td>-</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>10,371</td>\n",
       "      <td>-</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP_2021_2022 GSDP_2022_2023   Share  \\\n",
       "0     1                Maharashtra      3,108,022              -  13.17%   \n",
       "1     2                 Tamil Nadu      2,071,286      1,453,321   8.78%   \n",
       "2     3                  Karnataka      1,978,094      1,335,052   8.38%   \n",
       "3     4              Uttar Pradesh      1,975,595      1,318,027   8.37%   \n",
       "4     5                    Gujarat      1,928,683      1,475,629   8.17%   \n",
       "5     6                West Bengal      1,329,238        839,805   5.63%   \n",
       "6     7                  Rajasthan      1,193,489        784,655   5.06%   \n",
       "7     8             Andhra Pradesh      1,148,471        764,685   4.87%   \n",
       "8     9                  Telangana      1,124,204        715,157   4.76%   \n",
       "9    10             Madhya Pradesh      1,092,964        622,908   4.63%   \n",
       "10   11                     Kerala        934,542        616,189   3.96%   \n",
       "11   12                      Delhi        881,336        625,981   3.73%   \n",
       "12   13                    Haryana        868,905        587,198   3.68%   \n",
       "13   14                     Odisha        662,886        464,574   2.81%   \n",
       "14   15                      Bihar        650,302        442,473   2.76%   \n",
       "15   16                     Punjab        617,192        462,053   2.62%   \n",
       "16   17                      Assam        411,454        300,799   1.74%   \n",
       "17   18               Chhattisgarh        410,525        302,119   1.74%   \n",
       "18   19                  Jharkhand        358,863        259,800   1.52%   \n",
       "19   20                Uttarakhand        267,143        198,341   1.13%   \n",
       "20   21            Jammu & Kashmir        193,352        129,573   0.82%   \n",
       "21   22           Himachal Pradesh        172,162        133,372   0.73%   \n",
       "22   23                        Goa         84,266         59,867   0.36%   \n",
       "23   24                    Tripura         62,550         42,997   0.27%   \n",
       "24   25                 Chandigarh         46,096         33,879   0.20%   \n",
       "25   26                 Puducherry         43,810         28,849   0.19%   \n",
       "26   27                  Meghalaya         38,785         25,209   0.16%   \n",
       "27   28                     Sikkim         37,557         22,144   0.16%   \n",
       "28   29                    Manipur         36,594              -   0.16%   \n",
       "29   30          Arunachal Pradesh         34,775         21,085   0.15%   \n",
       "30   31                   Nagaland         31,038         18,993   0.13%   \n",
       "31   32                    Mizoram         27,824              -   0.12%   \n",
       "32   33  Andaman & Nicobar Islands         10,371              -   0.04%   \n",
       "\n",
       "        GDP  \n",
       "0   414.928  \n",
       "1   276.522  \n",
       "2   264.080  \n",
       "3   263.747  \n",
       "4   257.484  \n",
       "5   177.456  \n",
       "6   159.334  \n",
       "7   153.324  \n",
       "8   150.084  \n",
       "9   145.913  \n",
       "10  124.764  \n",
       "11  117.660  \n",
       "12  116.001  \n",
       "13   88.497  \n",
       "14   86.817  \n",
       "15   82.397  \n",
       "16   54.930  \n",
       "17   54.806  \n",
       "18   47.909  \n",
       "19   35.664  \n",
       "20   25.813  \n",
       "21   22.984  \n",
       "22   11.250  \n",
       "23    8.351  \n",
       "24    6.154  \n",
       "25    5.849  \n",
       "26    5.178  \n",
       "27    5.014  \n",
       "28    4.885  \n",
       "29    4.643  \n",
       "30    4.144  \n",
       "31    3.715  \n",
       "32    1.385  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':Rank,'State':State,'GSDP_2021_2022':GSDP_2021_2022,'GSDP_2022_2023':GSDP_2022_2023,'Share':Share,'GDP':GDP})\n",
    "df.head(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f776f481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eda85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5e3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b4bfa0f",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com. Url = https://github.com/ You have to find the following details:  A) Repository title   B) Repository description   C) Contributors count   D) Language used   \n",
    "# Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4753f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d6cc3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b5f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554a22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OS=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "OS.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d45c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b943b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_Title = []\n",
    "Repository_Description = []\n",
    "Contribution_Counts = []\n",
    "Language_Used = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01ef8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_tags=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "for i in repository_tags:\n",
    "    repository_title=i.text\n",
    "    Repository_Title.append(repository_title)\n",
    "    \n",
    "description_tags=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in description_tags:\n",
    "    description_title=i.text\n",
    "    Repository_Description.append(description_title)\n",
    "    \n",
    "count_tags=driver.find_elements(By.XPATH,'//a[2][@class=\"Link Link--muted d-inline-block mr-3\"]')\n",
    "for i in count_tags:\n",
    "    count_title=i.text\n",
    "    Contribution_Counts.append(count_title)\n",
    "    \n",
    "lenguage_tags=driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "for i in lenguage_tags:\n",
    "    lenguage_title=i.text\n",
    "    Language_Used.append(lenguage_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdbbf2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 22\n"
     ]
    }
   ],
   "source": [
    "print(len(Repository_Title),len(Repository_Description),len(Contribution_Counts),len(Language_Used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca58be0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Repository_Title</th>\n",
       "      <th>Repository_Description</th>\n",
       "      <th>Contribution_Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>massgravel / Microsoft-Activation-Scripts</td>\n",
       "      <td>A Windows and Office activator using HWID / Oh...</td>\n",
       "      <td>7,480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blealtan / efficient-kan</td>\n",
       "      <td>An efficient pure-PyTorch implementation of Ko...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HVision-NKU / StoryDiffusion</td>\n",
       "      <td>Create Magic Story!</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wandb / openui</td>\n",
       "      <td>OpenUI let's you describe UI using your imagin...</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AtotheY / saas-landingpage</td>\n",
       "      <td>https://map.sistilli.dev/public/coding/SaaS+Bo...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VinciGit00 / Scrapegraph-ai</td>\n",
       "      <td>Python scraper based on AI</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rasbt / LLMs-from-scratch</td>\n",
       "      <td>Implementing a ChatGPT-like LLM from scratch, ...</td>\n",
       "      <td>1,404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stirling-Tools / Stirling-PDF</td>\n",
       "      <td>#1 Locally hosted web application that allows ...</td>\n",
       "      <td>1,735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xM4ddy / OFGB</td>\n",
       "      <td>GUI Tool To Removes Ads From Various Places Ar...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>assafelovic / gpt-researcher</td>\n",
       "      <td>GPT based autonomous agent that does online co...</td>\n",
       "      <td>1,171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dockur / windows</td>\n",
       "      <td>Windows in a Docker container.</td>\n",
       "      <td>1,041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phidatahq / phidata</td>\n",
       "      <td>Memory, knowledge and tools for LLMs</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KindXiaoming / pykan</td>\n",
       "      <td>Kolmogorov Arnold Networks</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tangzhiyao / boss-show-time</td>\n",
       "      <td>展示boss直聘岗位的发布时间</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pydantic / logfire</td>\n",
       "      <td>Uncomplicated Observability for Python and bey...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lencx / ChatGPT</td>\n",
       "      <td>🔮 ChatGPT Desktop Application (Mac, Windows an...</td>\n",
       "      <td>5,423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apache / dolphinscheduler</td>\n",
       "      <td>Apache DolphinScheduler is the modern data orc...</td>\n",
       "      <td>4,420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ca110us / epeius</td>\n",
       "      <td>Deploy Trojan using a Serverless approach</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>commaai / openpilot</td>\n",
       "      <td>openpilot is an open source driver assistance ...</td>\n",
       "      <td>8,590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>codecrafters-io / build-your-own-x</td>\n",
       "      <td>Master programming by recreating your favorite...</td>\n",
       "      <td>24,698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>renovatebot / renovate</td>\n",
       "      <td>Universal dependency automation tool.</td>\n",
       "      <td>2,051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DataTalksClub / llm-zoomcamp</td>\n",
       "      <td>LLM Zoomcamp - a free online course about buil...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ChatGPTNextWeb / ChatGPT-Next-Web</td>\n",
       "      <td>A cross-platform ChatGPT/Gemini UI (Web / PWA ...</td>\n",
       "      <td>55,467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>airbnb / lottie-ios</td>\n",
       "      <td>An iOS library to natively render After Effect...</td>\n",
       "      <td>3,683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>StarRocks / starrocks</td>\n",
       "      <td>StarRocks, a Linux Foundation project, is a ne...</td>\n",
       "      <td>1,615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            (Repository_Title  \\\n",
       "0   massgravel / Microsoft-Activation-Scripts   \n",
       "1                    Blealtan / efficient-kan   \n",
       "2                HVision-NKU / StoryDiffusion   \n",
       "3                              wandb / openui   \n",
       "4                  AtotheY / saas-landingpage   \n",
       "5                 VinciGit00 / Scrapegraph-ai   \n",
       "6                   rasbt / LLMs-from-scratch   \n",
       "7               Stirling-Tools / Stirling-PDF   \n",
       "8                               xM4ddy / OFGB   \n",
       "9                assafelovic / gpt-researcher   \n",
       "10                           dockur / windows   \n",
       "11                        phidatahq / phidata   \n",
       "12                       KindXiaoming / pykan   \n",
       "13                tangzhiyao / boss-show-time   \n",
       "14                         pydantic / logfire   \n",
       "15                            lencx / ChatGPT   \n",
       "16                  apache / dolphinscheduler   \n",
       "17                           ca110us / epeius   \n",
       "18                        commaai / openpilot   \n",
       "19         codecrafters-io / build-your-own-x   \n",
       "20                     renovatebot / renovate   \n",
       "21               DataTalksClub / llm-zoomcamp   \n",
       "22          ChatGPTNextWeb / ChatGPT-Next-Web   \n",
       "23                        airbnb / lottie-ios   \n",
       "24                      StarRocks / starrocks   \n",
       "\n",
       "                               Repository_Description Contribution_Counts  \n",
       "0   A Windows and Office activator using HWID / Oh...               7,480  \n",
       "1   An efficient pure-PyTorch implementation of Ko...                  86  \n",
       "2                                 Create Magic Story!                 192  \n",
       "3   OpenUI let's you describe UI using your imagin...                 837  \n",
       "4   https://map.sistilli.dev/public/coding/SaaS+Bo...                  39  \n",
       "5                          Python scraper based on AI                 174  \n",
       "6   Implementing a ChatGPT-like LLM from scratch, ...               1,404  \n",
       "7   #1 Locally hosted web application that allows ...               1,735  \n",
       "8   GUI Tool To Removes Ads From Various Places Ar...                 118  \n",
       "9   GPT based autonomous agent that does online co...               1,171  \n",
       "10                     Windows in a Docker container.               1,041  \n",
       "11               Memory, knowledge and tools for LLMs                 736  \n",
       "12                         Kolmogorov Arnold Networks                 651  \n",
       "13                                    展示boss直聘岗位的发布时间                  11  \n",
       "14  Uncomplicated Observability for Python and bey...                  31  \n",
       "15  🔮 ChatGPT Desktop Application (Mac, Windows an...               5,423  \n",
       "16  Apache DolphinScheduler is the modern data orc...               4,420  \n",
       "17          Deploy Trojan using a Serverless approach                 264  \n",
       "18  openpilot is an open source driver assistance ...               8,590  \n",
       "19  Master programming by recreating your favorite...              24,698  \n",
       "20              Universal dependency automation tool.               2,051  \n",
       "21  LLM Zoomcamp - a free online course about buil...                  51  \n",
       "22  A cross-platform ChatGPT/Gemini UI (Web / PWA ...              55,467  \n",
       "23  An iOS library to natively render After Effect...               3,683  \n",
       "24  StarRocks, a Linux Foundation project, is a ne...               1,615  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'(Repository_Title':Repository_Title,'Repository_Description':Repository_Description,'Contribution_Counts':Contribution_Counts})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beda95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb2bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bcc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928e2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11d86c34",
   "metadata": {},
   "source": [
    "#  5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/  You have to find the following details:   A) Song name   B) Artist name   C) Last week rank   D) Peak rank   E) Weeks on board   \n",
    "\n",
    "# Note: - From the home page you have to click on the charts option then hot 100-page link through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e496d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e573ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def306a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7ba041",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot=driver.find_element(By.XPATH,'//a[@class=\"c-link  lrv-a-unstyle-link lrv-u-color-brand-primary:hover lrv-a-hover-effect lrv-u-whitespace-nowrap lrv-u-color-grey-dark\"]')\n",
    "hot.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e90af4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_Name = []\n",
    "Artist_Name = []\n",
    "Last_Weak_Rank = []\n",
    "Peak_Rank = []\n",
    "Weaks_On_Board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "017632fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_tags=driver.find_elements(By.XPATH,'//div[@class=\"chart-results-list // lrv-u-padding-t-150 lrv-u-padding-t-050@mobile-max\"]//div//ul//li//li//h3')\n",
    "for i in song_tags:\n",
    "    song_title=i.text\n",
    "    Song_Name.append(song_title)\n",
    "    \n",
    "    \n",
    "artist_tags=driver.find_elements(By.XPATH,'//div[@class=\"chart-results-list // lrv-u-padding-t-150 lrv-u-padding-t-050@mobile-max\"]//div//ul//ul//li[1]//span')\n",
    "for i in artist_tags:\n",
    "    artist_title=i.text\n",
    "    Artist_Name.append(artist_title)\n",
    "    \n",
    "    \n",
    "rank_tags=driver.find_elements(By.XPATH,'//li[4][@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]//span[1]')\n",
    "for i in rank_tags:\n",
    "    rank_title=i.text\n",
    "    Last_Weak_Rank.append(rank_title)\n",
    "    \n",
    "    \n",
    "peak_tags=driver.find_elements(By.XPATH,'//li[5][@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"]/span')\n",
    "for i in peak_tags:\n",
    "    peak_title=i.text\n",
    "    Peak_Rank.append(peak_title)\n",
    "    \n",
    "    \n",
    "weaks_tags=driver.find_elements(By.XPATH,'//li[6][@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]/span[1]')\n",
    "for i in weaks_tags:\n",
    "    weaks_title=i.text\n",
    "    Weaks_On_Board.append(weaks_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36e274ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Song_Name),len(Artist_Name),len(Last_Weak_Rank),len(Peak_Rank),len(Weaks_On_Board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c6153f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_Weak_Rank</th>\n",
       "      <th>Peak_Rank</th>\n",
       "      <th>Weaks_On_Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fortnight</td>\n",
       "      <td>Taylor Swift Featuring Post Malone</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Down Bad</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Can Do It With A Broken Heart</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Tortured Poets Department</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So Long, London</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Us Vs. Them</td>\n",
       "      <td>$uicideBoy$</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wine Into Whiskey</td>\n",
       "      <td>Tucker Wetmore</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Spin You Around (1/24)</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>89</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Soak City</td>\n",
       "      <td>310babii</td>\n",
       "      <td>82</td>\n",
       "      <td>53</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Selfish</td>\n",
       "      <td>Justin Timberlake</td>\n",
       "      <td>60</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Song_Name                         Artist_Name  \\\n",
       "0                         Fortnight  Taylor Swift Featuring Post Malone   \n",
       "1                          Down Bad                        Taylor Swift   \n",
       "2   I Can Do It With A Broken Heart                        Taylor Swift   \n",
       "3     The Tortured Poets Department                        Taylor Swift   \n",
       "4                   So Long, London                        Taylor Swift   \n",
       "..                              ...                                 ...   \n",
       "95                      Us Vs. Them                         $uicideBoy$   \n",
       "96                Wine Into Whiskey                      Tucker Wetmore   \n",
       "97           Spin You Around (1/24)                       Morgan Wallen   \n",
       "98                        Soak City                            310babii   \n",
       "99                          Selfish                   Justin Timberlake   \n",
       "\n",
       "   Last_Weak_Rank Peak_Rank Weaks_On_Board  \n",
       "0               -         1              1  \n",
       "1               -         2              1  \n",
       "2               -         3              1  \n",
       "3               -         4              1  \n",
       "4               -         5              1  \n",
       "..            ...       ...            ...  \n",
       "95              -        96              1  \n",
       "96             84        77              5  \n",
       "97             89        24             13  \n",
       "98             82        53             19  \n",
       "99             60        19             13  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Song_Name':Song_Name,'Artist_Name':Artist_Name,'Last_Weak_Rank':Last_Weak_Rank,'Peak_Rank':Peak_Rank,'Weaks_On_Board':Weaks_On_Board})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2b2efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596c451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13fd60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e62238a",
   "metadata": {},
   "source": [
    "#  6. Scrape the details of Highest selling novels.   A) Book name   B) Author name   C) Volumes sold   D) Publisher   E) Genre   Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10933c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c545f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e86496e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f1159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_Name = []\n",
    "Author_Name = []\n",
    "Volumes_Sold = []\n",
    "Publisher = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c96c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name_tags=driver.find_elements(By.XPATH,'//td[2][@class=\"left\"]')\n",
    "for i in book_name_tags:\n",
    "    book_name_title=i.text\n",
    "    Book_Name.append(book_name_title)\n",
    "    \n",
    "\n",
    "author_name_tags=driver.find_elements(By.XPATH,'//td[3][@class=\"left\"]')\n",
    "for i in author_name_tags:\n",
    "    author_name_title=i.text\n",
    "    Author_Name.append(author_name_title)\n",
    "    \n",
    "    \n",
    "sold_tags=driver.find_elements(By.XPATH,'//td[4][@class=\"left\"]')\n",
    "for i in sold_tags:\n",
    "    sold_title=i.text\n",
    "    Volumes_Sold.append(sold_title)\n",
    "    \n",
    "    \n",
    "publisher_tags=driver.find_elements(By.XPATH,'//td[5][@class=\"left\"]')\n",
    "for i in publisher_tags:\n",
    "    publisher_title=i.text\n",
    "    Publisher.append(publisher_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0258323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Book_Name),len(Author_Name),len(Volumes_Sold),len(Publisher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6222d5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Volumes_Sold</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_Name       Author_Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_Sold        Publisher  \n",
       "0     5,094,805       Transworld  \n",
       "1     4,475,152       Bloomsbury  \n",
       "2     4,200,654       Bloomsbury  \n",
       "3     4,179,479       Bloomsbury  \n",
       "4     3,758,936     Random House  \n",
       "..          ...              ...  \n",
       "95      807,311     Random House  \n",
       "96      794,201          Penguin  \n",
       "97      792,187  Scholastic Ltd.  \n",
       "98      791,507            Orion  \n",
       "99      791,095          Penguin  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Book_Name':Book_Name,'Author_Name':Author_Name,'Volumes_Sold':Volumes_Sold,'Publisher':Publisher})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4304e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590f0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c92bda46",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com.   Url = https://www.imdb.com/list/ls512407256/ You have to find the following details:   A) Name   B) Year span   c) Genre   D) Run time   E) Ratings   F) Votes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd7e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82eb9594",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b097568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.imdb.com/list/ls512407256/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68cc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Year_Span = []\n",
    "Genre = []\n",
    "Run_Time = []\n",
    "Ratings = []\n",
    "Votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82513c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]//a')\n",
    "for i in name_tags:\n",
    "    name_title=i.text\n",
    "    Name.append(name_title)\n",
    "    \n",
    "    \n",
    "year_tags=driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in year_tags:\n",
    "    year_title=i.text\n",
    "    Year_Span.append(year_title)\n",
    "    \n",
    "    \n",
    "genre_tags=driver.find_elements(By.XPATH,'//span[@class=\"certificate\"]')\n",
    "for i in genre_tags:\n",
    "    genre_title=i.text\n",
    "    Genre.append(genre_title)\n",
    "    \n",
    "    \n",
    "run_tags=driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in run_tags:\n",
    "    run_title=i.text\n",
    "    Run_Time.append(run_title)\n",
    "    \n",
    "    \n",
    "rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]')\n",
    "for i in rating_tags:\n",
    "    rating_title=i.text\n",
    "    Ratings.append(rating_title)\n",
    "    \n",
    "\n",
    "votes_tags=driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "for i in votes_tags:\n",
    "    votes_title=i.text\n",
    "    Votes.append(votes_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346e4d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Year_Span),len(Genre),len(Run_Time),len(Ratings),len(Votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d3ccbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>60 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,287,806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,338,628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,083,469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>315,813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>276,572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>True Detective</td>\n",
       "      <td>(2014– )</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>657,388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011–2017)</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>163,412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The OA</td>\n",
       "      <td>(2016–2019)</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>115,995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989– )</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>436,347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>(2004–2012)</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>139,913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name    Year_Span  Genre Run_Time Ratings      Votes\n",
       "0        Game of Thrones  (2011–2019)  TV-MA   60 min     9.2  2,287,806\n",
       "1        Stranger Things  (2016–2025)  TV-14   60 min     8.7  1,338,628\n",
       "2       The Walking Dead  (2010–2022)  TV-MA   45 min     8.1  1,083,469\n",
       "3         13 Reasons Why  (2017–2020)  TV-MA   60 min     7.5    315,813\n",
       "4                The 100  (2014–2020)  TV-14   43 min     7.6    276,572\n",
       "..                   ...          ...    ...      ...     ...        ...\n",
       "95        True Detective     (2014– )  TV-MA   60 min     8.9    657,388\n",
       "96             Teen Wolf  (2011–2017)  TV-14   41 min     7.7    163,412\n",
       "97                The OA  (2016–2019)  TV-MA   60 min     7.8    115,995\n",
       "98          The Simpsons     (1989– )  TV-14   22 min     8.7    436,347\n",
       "99  Desperate Housewives  (2004–2012)  TV-14   45 min     7.6    139,913\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':Name,'Year_Span':Year_Span,'Genre':Genre,'Run_Time':Run_Time,'Ratings':Ratings,'Votes':Votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda04c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d905a70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3ace0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e20b2eb5",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories.   Url = https://archive.ics.uci.edu/  You have to find the following details:   A) Dataset name   B) Data type   C) Task   D) Attribute type   E) No of instances   F) No of attribute G) Year   \n",
    "# Note: - from the home page you have to go to the Show All Dataset page through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314ded21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4154f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b13be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0ea272",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "Dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cabf96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Name = []\n",
    "Data_Type = []\n",
    "Task = []\n",
    "Attribute_Type = []\n",
    "No_of_Instances = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b88f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetname_tags=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in datasetname_tags:\n",
    "    datasetname_title=i.text\n",
    "    Dataset_Name.append(datasetname_title)\n",
    "    \n",
    "datatype_tags=driver.find_elements(By.XPATH,'//div[@class=\"rounded-box bg-base-100\"]//div//div//div//div[2]//span')\n",
    "for i in datatype_tags:\n",
    "    datatype_title=i.text\n",
    "    Data_Type.append(datatype_title)\n",
    "    \n",
    "task_tags=driver.find_elements(By.XPATH,'//div[@class=\"rounded-box bg-base-100\"]//div//div//div//div[1]//span')\n",
    "for i in task_tags:\n",
    "    task_title=i.text\n",
    "    Task.append(task_title)\n",
    "    \n",
    "attribute_tags=driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]//td[2]')\n",
    "for i in attribute_tags:\n",
    "    attribute_title=i.text\n",
    "    Attribute_Type.append(attribute_title)\n",
    "    \n",
    "instances_tags=driver.find_elements(By.XPATH,'//div[@class=\"rounded-box bg-base-100\"]//div//div//div//div[3]//span')\n",
    "for i in instances_tags:\n",
    "    instances_title=i.text\n",
    "    No_of_Instances.append(instances_title)\n",
    "    \n",
    "year_tags=driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]//td[3]')\n",
    "for i in year_tags:\n",
    "    year_title=i.text\n",
    "    Year.append(year_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e582dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset_Name),len(Data_Type),len(Task),len(Attribute_Type),len(No_of_Instances),len(Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dba4076b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_Type</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8/14/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset_Name                  Data_Type  \\\n",
       "0                                  Iris                    Tabular   \n",
       "1                         Heart Disease               Multivariate   \n",
       "2                              Dry Bean               Multivariate   \n",
       "3            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "4                                 Adult               Multivariate   \n",
       "5  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "6                                Raisin               Multivariate   \n",
       "7                                  Wine                    Tabular   \n",
       "8                          Wine Quality               Multivariate   \n",
       "9                              Diabetes  Multivariate, Time-Series   \n",
       "\n",
       "                         Task              Attribute_Type   No_of_Instances  \\\n",
       "0              Classification                        Real     150 Instances   \n",
       "1              Classification  Categorical, Integer, Real     303 Instances   \n",
       "2              Classification               Integer, Real  13.61K Instances   \n",
       "3              Classification                        Real   3.81K Instances   \n",
       "4              Classification        Categorical, Integer  48.84K Instances   \n",
       "5              Classification                        Real     569 Instances   \n",
       "6              Classification               Real, Integer     900 Instances   \n",
       "7              Classification               Integer, Real     178 Instances   \n",
       "8  Classification, Regression                        Real    4.9K Instances   \n",
       "9              Classification        Categorical, Integer       1 Instances   \n",
       "\n",
       "        Year  \n",
       "0   7/1/1988  \n",
       "1   7/1/1988  \n",
       "2  9/14/2020  \n",
       "3  10/6/2019  \n",
       "4   5/1/1996  \n",
       "5  11/1/1995  \n",
       "6  8/14/2023  \n",
       "7   7/1/1991  \n",
       "8  10/7/2009  \n",
       "9        N/A  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Dataset_Name':Dataset_Name,'Data_Type':Data_Type,'Task':Task,'Attribute_Type':Attribute_Type,'No_of_Instances':No_of_Instances,'Year':Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b5262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e80e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f4bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
